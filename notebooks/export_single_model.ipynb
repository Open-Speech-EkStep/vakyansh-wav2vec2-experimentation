{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d9c8a4a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fairseq import tasks, utils, checkpoint_utils\n",
    "import torch\n",
    "from argparse import Namespace\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ad8aff4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = Namespace(**{\n",
    "    'task':'audio_finetuning',\n",
    "    'data':'/home/harveen/fair/vakyansh-wav2vec2-experimentation/checkpoints/finetuning',\n",
    "    'criterion':'ctc'\n",
    "})\n",
    "task = tasks.setup_task(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4619fdd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-24 10:58:48 | INFO | fairseq.models.wav2vec.wav2vec2_asr | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 1, 'log_format': 'json', 'log_file': None, 'tensorboard_logdir': '/home/harveen.chadha/vakyansh-wav2vec2-experimentation/logs/pretraining/tensorboard_2021-05-26_12-40-52', 'wandb_project': 'EKSTEP-PRETRAINING', 'azureml_logging': False, 'seed': 2021, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 16, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': 'tcp://localhost:18706', 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'legacy_ddp', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_algorithm': 'LocalSGD', 'localsgd_frequency': 3, 'nprocs_per_node': 16, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'distributed_num_procs': 16}, 'dataset': {'_name': None, 'num_workers': 6, 'skip_invalid_size_inputs_valid_test': True, 'max_tokens': 5400000, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 5400000, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 400000, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [4], 'lr': [0.0005], 'stop_min_lr': -1.0, 'use_bmuf': False}, 'checkpoint': {'_name': None, 'save_dir': '/home/harveen.chadha/vakyansh-wav2vec2-experimentation/checkpoints/pretraining', 'restore_file': '/home/harveen.chadha/vakyansh-wav2vec2-experimentation/checkpoints/pretraining/checkpoint_584_15000.pt', 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 5000, 'keep_interval_updates': 1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': 5, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 16}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': {'_name': 'wav2vec2', 'extractor_mode': 'default', 'encoder_layers': 12, 'encoder_embed_dim': 768, 'encoder_ffn_embed_dim': 3072, 'encoder_attention_heads': 12, 'activation_fn': 'gelu', 'dropout': 0.0, 'attention_dropout': 0.0, 'activation_dropout': 0.1, 'encoder_layerdrop': 0.1, 'dropout_input': 0.0, 'dropout_features': 0.1, 'final_dim': 256, 'layer_norm_first': False, 'conv_feature_layers': '[(512, 10, 5)] + [(512, 3, 2)] * 4 + [(512,2,2)] + [(512,2,2)]', 'conv_bias': False, 'logit_temp': 0.1, 'quantize_targets': True, 'quantize_input': False, 'same_quantizer': False, 'target_glu': False, 'feature_grad_mult': 0.0, 'latent_vars': 320, 'latent_groups': 2, 'latent_dim': 0, 'mask_length': 10, 'mask_prob': 0.5, 'mask_selection': static, 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'mask_channel_length': 64, 'mask_channel_prob': 0.1, 'mask_channel_selection': static, 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'mask_channel_min_space': 1, 'num_negatives': 100, 'negatives_from_everywhere': False, 'cross_sample_negatives': 0, 'codebook_negatives': 0, 'conv_pos': 128, 'conv_pos_groups': 16, 'latent_temp': [2.0, 0.5, 0.999995]}, 'task': {'data': '/home/harveen.chadha/vakyansh-wav2vec2-experimentation/data/pretraining', 'labels': None, 'sample_rate': 16000, 'normalize': False, 'enable_padding': False, 'max_sample_size': 250000, 'min_sample_size': 32000, 'num_batch_buckets': 0, 'precompute_mask_indices': False, 'tpu': False, '_name': 'audio_pretraining'}, 'criterion': None, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9,0.98)', 'adam_eps': 1e-06, 'weight_decay': 0.01, 'use_old_adam': False, 'tpu': False, 'lr': [0.0005]}, 'lr_scheduler': None, 'scoring': None, 'bpe': None, 'tokenizer': None, 'job_logging_cfg': {'version': 1, 'formatters': {'simple': {'format': '[%(asctime)s][%(name)s][%(levelname)s] - %(message)s'}}, 'handlers': {'console': {'class': 'logging.StreamHandler', 'formatter': 'simple', 'stream': 'ext://sys.stdout'}, 'file': {'class': 'logging.FileHandler', 'formatter': 'simple', 'filename': 'hydra_train.log'}}, 'root': {'level': 'INFO', 'handlers': ['console', 'file']}, 'disable_existing_loggers': False}}\n"
     ]
    },
    {
     "ename": "PicklingError",
     "evalue": "Can't pickle <enum 'Choices'>: attribute lookup Choices on fairseq.dataclass.constants failed",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPicklingError\u001b[0m                             Traceback (most recent call last)",
      "Input \u001b[0;32mIn [8]\u001b[0m, in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m model \u001b[38;5;241m=\u001b[39m model[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m      4\u001b[0m model\u001b[38;5;241m.\u001b[39meval()\n\u001b[0;32m----> 6\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m/home/harveen/fair/vakyansh-wav2vec2-experimentation/checkpoints/single_model/test.pt\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/envs/fairseq/lib/python3.8/site-packages/torch/serialization.py:380\u001b[0m, in \u001b[0;36msave\u001b[0;34m(obj, f, pickle_module, pickle_protocol, _use_new_zipfile_serialization)\u001b[0m\n\u001b[1;32m    378\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _use_new_zipfile_serialization:\n\u001b[1;32m    379\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m _open_zipfile_writer(opened_file) \u001b[38;5;28;01mas\u001b[39;00m opened_zipfile:\n\u001b[0;32m--> 380\u001b[0m         \u001b[43m_save\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopened_zipfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpickle_module\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpickle_protocol\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    381\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m    382\u001b[0m _legacy_save(obj, opened_file, pickle_module, pickle_protocol)\n",
      "File \u001b[0;32m/opt/conda/envs/fairseq/lib/python3.8/site-packages/torch/serialization.py:589\u001b[0m, in \u001b[0;36m_save\u001b[0;34m(obj, zip_file, pickle_module, pickle_protocol)\u001b[0m\n\u001b[1;32m    587\u001b[0m pickler \u001b[38;5;241m=\u001b[39m pickle_module\u001b[38;5;241m.\u001b[39mPickler(data_buf, protocol\u001b[38;5;241m=\u001b[39mpickle_protocol)\n\u001b[1;32m    588\u001b[0m pickler\u001b[38;5;241m.\u001b[39mpersistent_id \u001b[38;5;241m=\u001b[39m persistent_id\n\u001b[0;32m--> 589\u001b[0m \u001b[43mpickler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdump\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    590\u001b[0m data_value \u001b[38;5;241m=\u001b[39m data_buf\u001b[38;5;241m.\u001b[39mgetvalue()\n\u001b[1;32m    591\u001b[0m zip_file\u001b[38;5;241m.\u001b[39mwrite_record(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata.pkl\u001b[39m\u001b[38;5;124m'\u001b[39m, data_value, \u001b[38;5;28mlen\u001b[39m(data_value))\n",
      "\u001b[0;31mPicklingError\u001b[0m: Can't pickle <enum 'Choices'>: attribute lookup Choices on fairseq.dataclass.constants failed"
     ]
    }
   ],
   "source": [
    "model, cfg, task = checkpoint_utils.load_model_ensemble_and_task(['/home/harveen/fair/vakyansh-wav2vec2-experimentation/checkpoints/finetuning/him_modified.pt'], task=task,\n",
    "                                                                         arg_overrides={\"w2v_path\": \"/home/harveen/fair/vakyansh-wav2vec2-experimentation/checkpoints/finetuning/clsril_modified.pt\"})\n",
    "model = model[0]\n",
    "model.eval()\n",
    "\n",
    "torch.save(model, '/home/harveen/fair/vakyansh-wav2vec2-experimentation/checkpoints/single_model/test.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "eda7880f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchaudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c6ed87d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "arrr, _ = torchaudio.load('../evaluations/taarini_without_numbers/004-M-23_001.wav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ae348b77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0000,  0.0000,  0.0000,  ..., -0.0003, -0.0003, -0.0003]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arrr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7fbfad50",
   "metadata": {},
   "outputs": [],
   "source": [
    "logits = model(source=arrr, padding_mask=None)[\"encoder_out\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "73680a63",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_ids = torch.argmax(logits[:, 0], dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "97c24ec3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0, 52,  0, 64,  0,  0,  0,\n",
       "         0,  0, 30,  0,  0,  0,  0,  0,  0,  0, 47,  0,  0,  4,  4,  0,  0,  0,\n",
       "        46,  0,  0, 63,  0,  0, 45,  0, 47,  0,  0,  0,  4,  0, 52,  0,  0, 61,\n",
       "         0,  0, 46,  0,  0, 55,  0,  0, 30,  0,  0,  0, 61,  0,  0,  0,  0, 27,\n",
       "         0,  0,  0,  0,  4, 20,  0, 61,  0,  0,  0,  0,  4,  0, 25,  0,  0,  0,\n",
       "         0, 56,  0,  0,  0,  0,  0, 27,  0,  0,  0,  4,  0, 20,  0, 61,  0,  0,\n",
       "         4,  0,  0,  0, 20,  0,  0,  4,  0,  0, 42,  0,  0,  0, 52,  0, 57,  0,\n",
       "         0, 35,  0,  0,  4,  4,  0,  0,  0,  8,  0,  0, 25,  0,  0, 66,  0, 26,\n",
       "         0,  0,  0,  0,  0, 54,  0,  0,  0,  0,  0,  4,  0, 52,  0,  0, 62,  0,\n",
       "         0,  0,  0,  0,  4,  0,  0, 20,  0, 66, 66,  0, 45,  0, 54,  0,  0,  0,\n",
       "         0,  4,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "24cddf32",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_ = []\n",
    "with open('/home/harveen/fair/vakyansh-wav2vec2-experimentation/checkpoints/finetuning/dict.ltr.txt') as file:\n",
    "    dict_ = file.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "63430434",
   "metadata": {},
   "outputs": [],
   "source": [
    "chars = [item.split(' ')[0] for item in dict_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "49019448",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "json_dict = {\"<s>\": 0, \"<pad>\": 1, \"</s>\": 2, \"<unk>\": 3}\n",
    "for index, i in enumerate(chars):\n",
    "    json_dict[i] = index + 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a46ad3be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from itertools import groupby\n",
    "\n",
    "class Decoder:\n",
    "    def __init__(self, json_dict):\n",
    "        self.dict = json_dict\n",
    "        self.look_up = np.asarray(list(self.dict.keys()))\n",
    "\n",
    "    def decode(self, ids):\n",
    "        converted_tokens = self.look_up[ids]\n",
    "        fused_tokens = [tok[0] for tok in groupby(converted_tokens)]\n",
    "        output = ' '.join(''.join(''.join(fused_tokens).split(\"<s>\")).split(\"|\"))\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a34fa300",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction:  होटल रॉयल हेरिटेज के चीज के क बहुत अच्छा है क्या \n"
     ]
    }
   ],
   "source": [
    "decoder = Decoder(json_dict=json_dict)\n",
    "print(\"Prediction: \", decoder.decode(predicted_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "3d9cb00e",
   "metadata": {},
   "outputs": [],
   "source": [
    "look_up = np.asarray(list(json_dict.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "5984bec1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['<s>', '<pad>', '</s>', '<unk>', '|', 'ँ', 'ं', 'ः', 'अ', 'आ', 'इ',\n",
       "       'ई', 'उ', 'ऊ', 'ऋ', 'ए', 'ऐ', 'ऑ', 'ओ', 'औ', 'क', 'ख', 'ग', 'घ',\n",
       "       'ङ', 'च', 'छ', 'ज', 'झ', 'ञ', 'ट', 'ठ', 'ड', 'ढ', 'ण', 'त', 'थ',\n",
       "       'द', 'ध', 'न', 'प', 'फ', 'ब', 'भ', 'म', 'य', 'र', 'ल', 'व', 'श',\n",
       "       'ष', 'स', 'ह', '़', 'ा', 'ि', 'ी', 'ु', 'ू', 'ृ', 'ॅ', 'े', 'ै',\n",
       "       'ॉ', 'ो', 'ौ', '्'], dtype='<U5')"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "look_up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "10fa6080",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['<s>', '<s>', '<s>', '<s>', '<s>', '<s>', '<s>', '<s>', '<s>',\n",
       "       '<s>', '<s>', '<s>', '<s>', '<s>', '<s>', '<s>', '<s>', '<s>',\n",
       "       '<s>', '<s>', '<s>', '<s>', '<s>', '<s>', '<s>', '<s>', '<s>',\n",
       "       '<s>', '<s>', '<s>', '<s>', '<s>', '<s>', '<s>', '<s>', '<s>',\n",
       "       '<s>', '<s>', '<s>', '<s>', '<s>', '<s>', '<s>', '<s>', '<s>',\n",
       "       '<s>', '<s>', '<s>', 'ह', '<s>', 'ो', '<s>', '<s>', '<s>', '<s>',\n",
       "       '<s>', 'ट', '<s>', '<s>', '<s>', '<s>', '<s>', '<s>', '<s>', 'ल',\n",
       "       '<s>', '<s>', '|', '|', '<s>', '<s>', '<s>', 'र', '<s>', '<s>',\n",
       "       'ॉ', '<s>', '<s>', 'य', '<s>', 'ल', '<s>', '<s>', '<s>', '|',\n",
       "       '<s>', 'ह', '<s>', '<s>', 'े', '<s>', '<s>', 'र', '<s>', '<s>',\n",
       "       'ि', '<s>', '<s>', 'ट', '<s>', '<s>', '<s>', 'े', '<s>', '<s>',\n",
       "       '<s>', '<s>', 'ज', '<s>', '<s>', '<s>', '<s>', '|', 'क', '<s>',\n",
       "       'े', '<s>', '<s>', '<s>', '<s>', '|', '<s>', 'च', '<s>', '<s>',\n",
       "       '<s>', '<s>', 'ी', '<s>', '<s>', '<s>', '<s>', '<s>', 'ज', '<s>',\n",
       "       '<s>', '<s>', '|', '<s>', 'क', '<s>', 'े', '<s>', '<s>', '|',\n",
       "       '<s>', '<s>', '<s>', 'क', '<s>', '<s>', '|', '<s>', '<s>', 'ब',\n",
       "       '<s>', '<s>', '<s>', 'ह', '<s>', 'ु', '<s>', '<s>', 'त', '<s>',\n",
       "       '<s>', '|', '|', '<s>', '<s>', '<s>', 'अ', '<s>', '<s>', 'च',\n",
       "       '<s>', '<s>', '्', '<s>', 'छ', '<s>', '<s>', '<s>', '<s>', '<s>',\n",
       "       'ा', '<s>', '<s>', '<s>', '<s>', '<s>', '|', '<s>', 'ह', '<s>',\n",
       "       '<s>', 'ै', '<s>', '<s>', '<s>', '<s>', '<s>', '|', '<s>', '<s>',\n",
       "       'क', '<s>', '्', '्', '<s>', 'य', '<s>', 'ा', '<s>', '<s>', '<s>',\n",
       "       '<s>', '|', '<s>', '<s>', '<s>', '<s>', '<s>', '<s>', '<s>', '<s>',\n",
       "       '<s>', '<s>', '<s>', '<s>', '<s>', '<s>', '<s>', '<s>', '<s>',\n",
       "       '<s>', '<s>', '<s>', '<s>', '<s>', '<s>', '<s>', '<s>', '<s>',\n",
       "       '<s>', '<s>', '<s>', '<s>', '<s>', '<s>', '<s>', '<s>', '<s>',\n",
       "       '<s>', '<s>', '<s>', '<s>', '<s>', '<s>', '<s>', '<s>', '<s>',\n",
       "       '<s>', '<s>', '<s>', '<s>', '<s>'], dtype='<U5')"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "converted_tokens = look_up[predicted_ids]\n",
    "converted_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "a3a331f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'होटल रॉयल हेरिटेज के चीज के क बहुत अच्छा है क्या '"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ft = [tok[0] for tok in groupby(converted_tokens)]\n",
    "' '.join(''.join(''.join(ft).split(\"<s>\")).split('|'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb2543e8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
